{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iyuB421EBOKn"},"outputs":[],"source":[" # Import libraries\n","!pip install split-folders\n","import splitfolders\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","from IPython.display import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imread\n","from osgeo import gdal\n","from google.colab import drive\n","from google.colab import files\n","\n","# !unzip \"/content/drive/MyDrive/bioinformatics/data.zip\" -d \"/content/drive/MyDrive/bioinformatics/\"\n","\n","\n","# Check GPU availability\n","if tf.config.list_physical_devices(\"GPU\"):\n","  print(\"GPU available!\")\n","else:\n","  print(\"GPU not available!\")\n","\n","# try:\n","#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","# except ValueError:\n","#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","# tf.config.experimental_connect_to_cluster(tpu)\n","# tf.tpu.experimental.initialize_tpu_system(tpu)\n","# tpu_strategy = tf.distribute.TPUStrategy(tpu)"]},{"cell_type":"markdown","metadata":{"id":"ezx6L-8pa7FI"},"source":["# Getting Familiar with the Data\n","\n","## Putting the training data filenames and labels into a CSV file\n","This step is performed once to get all the data in a CSV file with the appropriate label. Once that's done, the code is commented out!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vK4ba7_mB-i7"},"outputs":[],"source":["# Create data frame of data with labels\n","def create_dataframe(benign_directory, malignant_directory):\n","  \n","  BENIGN = 0\n","  MALIGNANT = 1\n","  benign_tumors = []\n","  malignant_tumors = []\n","  benign_dictionary = {}\n","  malignant_dictionary = {}\n","  tumor_dictionary = {}\n","\n","  if malignant_directory == 0:\n","    for benign_name in (os.listdir(benign_directory)):\n","      benign_tumors.append(benign_name)\n","    for key in benign_tumors:\n","      benign_dictionary[key] = BENIGN\n","\n","    # Create a data frame of labels\n","    labels_unshuffled = pd.DataFrame()\n","    labels_unshuffled[\"ID Benign\"] = benign_dictionary.keys()\n","    labels_unshuffled[\"Target\"] = benign_dictionary.values()\n","    labels = labels_unshuffled.sample(frac = 1).reset_index(drop = True)\n","    return labels\n","\n","  elif benign_directory == 0:\n","    for malignant_name in (os.listdir(malignant_directory)):\n","      malignant_tumors.append(malignant_name)\n","\n","    for key2 in malignant_tumors:\n","      malignant_dictionary[key2] = MALIGNANT\n","\n","    # Create a data frame of labels\n","    labels_unshuffled = pd.DataFrame()\n","    labels_unshuffled[\"ID Malignant\"] = malignant_dictionary.keys()\n","    labels_unshuffled[\"Target\"] = malignant_dictionary.values()\n","    labels = labels_unshuffled.sample(frac = 1).reset_index(drop = True)\n","    return labels\n","\n","  else:\n","    for benign_name in (os.listdir(benign_directory)):\n","      benign_tumors.append(benign_name)\n","    for key in benign_tumors:\n","      tumor_dictionary[key] = BENIGN\n","\n","    for malignant_name in (os.listdir(malignant_directory)):\n","      malignant_tumors.append(malignant_name)\n","\n","    for key2 in malignant_tumors:\n","      tumor_dictionary[key2] = MALIGNANT\n","    \n","    # Create a data frame of labels\n","    labels_unshuffled = pd.DataFrame()\n","    labels_unshuffled[\"ID\"] = tumor_dictionary.keys()\n","    labels_unshuffled[\"Target\"] = tumor_dictionary.values()\n","    labels = labels_unshuffled.sample(frac = 1).reset_index(drop = True)\n","    return labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5br47RRILTQ"},"outputs":[],"source":["# Uncomment to save as CSV file and to download\n","benign_directory = \"/content/drive/MyDrive/bioinformatics/data/train/benign\"\n","malignant_directory = \"/content/drive/MyDrive/bioinformatics/data/train/malignant\"\n","# labels = create_dataframe(benign_directory, malignant_directory)\n","# labels.to_csv('labels.csv')\n","# files.download('labels.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQDAGFqSO4f8"},"outputs":[],"source":["labels = pd.read_csv(\"/content/drive/MyDrive/bioinformatics/data/labels.csv\", index_col = 0)\n","labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0x94yjmdxPE"},"outputs":[],"source":["benign = 0\n","malignant = 0\n","for tumor_type in labels[\"Target\"]:\n","  if tumor_type == 0:\n","    benign += 1\n","  elif tumor_type == 1:\n","    malignant += 1\n","\n","print(f\"There are {benign} benign tumors and {malignant} malignant tumors in the training data.\")"]},{"cell_type":"markdown","metadata":{"id":"C_9J2i5oeEzp"},"source":["## Visualizing the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tliSQJZqfA84"},"outputs":[],"source":["# Turn images into tensors\n","def image_to_tensor(image_path):\n","  \n","  image = imread(image_path)\n","  image = tf.constant(image)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KDeLHxUgZQs"},"outputs":[],"source":["BENIGN = 0\n","MALIGNANT = 1\n","# from tensorflow.python.ops.gen_image_ops import image_projective_transform_v2\n","directory = \"/content/drive/MyDrive/bioinformatics/data/train_all/\"\n","paths = [directory + filename for filename in labels[\"ID\"] ]\n","paths\n","\n","def visualize_images(paths, num_images):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    image = image_to_tensor(paths[i])\n","    ax = plt.subplot(5, 4, i + 1)\n","    plt.xlabel(str(i))\n","    plt.imshow(image)\n","\n","    if labels[\"Target\"][i] == BENIGN:\n","      plt.title(\"Benign\")\n","    elif labels[\"Target\"][i] == MALIGNANT:\n","      plt.title(\"Malignant\")\n","    plt.axis(True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNVcWR6Hm6Pt"},"outputs":[],"source":["visualize_images(paths, 20)"]},{"cell_type":"markdown","metadata":{"id":"SqU8_XqG7d3a"},"source":["### Image Shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jG-ItE2c7l9l"},"outputs":[],"source":["image = image_to_tensor(paths[0])\n","image.shape"]},{"cell_type":"markdown","metadata":{"id":"5HkgzhbN382o"},"source":["# Building the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WE-UH-f5fl7"},"outputs":[],"source":["# Define the layers to use\n","layers = [tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\", input_shape = (460, 700, 3)),\n","          \n","          tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\"),\n","          tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n","\n","          tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"),\n","          tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n","\n","          tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = \"relu\"),\n","          tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n","\n","          tf.keras.layers.Dropout(rate = 0.25),\n","          tf.keras.layers.Flatten(),\n","\n","          tf.keras.layers.Dense(units = 64, activation = \"relu\"),\n","          tf.keras.layers.Dropout(rate = 0.25),\n","\n","          tf.keras.layers.Dense(units = 1, activation = \"sigmoid\")\n","          ]\n","\n","# Feed the layers to the model\n","metric_list = [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n","           tf.keras.metrics.TruePositives(), tf.keras.metrics.FalsePositives(),\n","           tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalseNegatives()]\n","model = tf.keras.Sequential(layers)\n","model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = metric_list)\n","print(model.summary())"]},{"cell_type":"markdown","metadata":{"id":"14EMZikbUhpz"},"source":["## Setting Up the Directories and Data Generators"]},{"cell_type":"markdown","metadata":{"id":"YVqriUHH2J7C"},"source":["Split the training data into training and validation data. Comment out when directory is set up."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zo0F3xbAZe4o"},"outputs":[],"source":["# main_directory = \"/content/drive/MyDrive/bioinformatics/data/train\"\n","# splitfolders.ratio(main_directory, output = \"/content/drive/MyDrive/bioinformatics/data/train_val_split\", seed = 42, ratio = (0.85, 0.15), group_prefix = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKzPjF9-Wp8I"},"outputs":[],"source":["# train_directory = \"/content/drive/MyDrive/bioinformatics/data/train\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Btwml-u5rezu"},"outputs":[],"source":["train = \"/content/drive/MyDrive/bioinformatics/data/train_val_split/train\"\n","validate = \"/content/drive/MyDrive/bioinformatics/data/train_val_split/val\"\n","test = \"/content/drive/MyDrive/bioinformatics/data/test\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wVxC3aWSd0o"},"outputs":[],"source":["# Create data generators\n","train_data_generation = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range = 0.2, shear_range = 0.2, rescale = 1. / 255, horizontal_flip = True)\n","validate_data_generation = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255)\n","test_data_generation = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255)\n","\n","train_data = train_data_generation.flow_from_directory(directory = train, target_size = (460, 700), batch_size = 16, class_mode = \"binary\")\n","validate_data = validate_data_generation.flow_from_directory(directory = validate, target_size = (460, 700), batch_size = 16, class_mode = \"binary\")\n","test_data = train_data_generation.flow_from_directory(directory = test, target_size = (460, 700), batch_size = 16, class_mode = \"binary\")\n","\n","print(\"Train Data Classes: \", train_data.class_indices)\n","print(\"Validate Data Classes: \", validate_data.class_indices)\n","print(\"Test Data Classes: \", test_data.class_indices)"]},{"cell_type":"markdown","metadata":{"id":"tmi7Ic9qWqvk"},"source":["## Creating Early Stopping Callback and Checkpoint for Saving the Model\n","\n","Helps prevent the model from overfitting by putting a stop to training if there are no improvements to the evaluation metrics passed to it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-CNCjCCYd-h"},"outputs":[],"source":["# Define the callbacks\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 5, verbose = 1, mode = \"auto\")\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/bioinformatics/breast-cancer-CNN.h5\", monitor = \"val_accuracy\", verbose = 1, mode = \"auto\", save_best_only = True)\n","call_backs = [early_stopping, checkpoint]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYOL4hWuZzqW"},"outputs":[],"source":["# Fit the model\n","model_fit = model.fit(x = train_data, epochs = 30, verbose = 1, validation_data = validate_data, callbacks = call_backs)\n","history = model_fit.history"]},{"cell_type":"markdown","metadata":{"id":"AjUP-JGZmTGL"},"source":["## Storing Metric Values for Training and Validation Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZsCHTUk6muW"},"outputs":[],"source":["train_accuracy = history[\"accuracy\"]\n","train_loss = history[\"loss\"]\n","train_precision = history[\"precision\"]\n","train_recall = history[\"recall\"]\n","train_tp = history[\"true_positives\"]\n","train_fp = history[\"false_positives\"]\n","train_tn = history[\"true_negatives\"]\n","train_fn = history[\"false_negatives\"]\n","\n","validation_accuracy = history[\"val_accuracy\"]\n","validation_loss = history[\"val_loss\"]\n","validation_precision = history[\"val_precision\"]\n","validation_recall = history[\"val_recall\"]\n","validation_tp = history[\"val_true_positives\"]\n","validation_fp = history[\"val_false_positives\"]\n","validation_tn = history[\"val_true_negatives\"]\n","validation_fn = history[\"val_false_negatives\"]"]},{"cell_type":"markdown","metadata":{"id":"NRIr7I_SmvOe"},"source":["### Plotting Results\n","* Train Accuracy vs. Validation Accuracy\n","* Train Loss vs. Validation Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5i1vAoKa2xm"},"outputs":[],"source":["train_acc, = plt.plot(train_accuracy, c = \"green\")\n","validate_acc, = plt.plot(validation_accuracy, c = \"red\")\n","plt.title(\"Train Accuracy vs. Validation Accuracy\")\n","plt.legend([train_acc, validate_acc],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHky0LJShAb4"},"outputs":[],"source":["train_los, = plt.plot(train_loss, c = \"green\")\n","validate_los, = plt.plot(validation_loss, c = \"red\")\n","plt.title(\"Train Loss vs. Validation Loss\")\n","plt.legend([train_los, validate_los],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dIt_PzIqhnfQ"},"source":["# Loading the Model and Using it on the Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asmmalpOuyMM"},"outputs":[],"source":["model_load = tf.keras.models.load_model(\"/content/drive/MyDrive/bioinformatics/breast-cancer-CNN.h5\")\n","model_load.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNGm1sm5u83h"},"outputs":[],"source":["test_evaluation = model_load.evaluate(x = test_data)"]},{"cell_type":"markdown","metadata":{"id":"JdjNF7a8mhUb"},"source":["## Storing Metric Values for Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJru0nXmhZl-"},"outputs":[],"source":["LOSS = 0\n","ACCURACY = 1\n","PRECISION = 2\n","RECALL =  3\n","TP = 4\n","FP = 5\n","TN = 6\n","FN = 7\n","\n","test_loss = test_evaluation[LOSS]\n","test_accuracy = test_evaluation[ACCURACY]\n","test_precision = test_evaluation[PRECISION]\n","test_recall = test_evaluation[RECALL]\n","test_tp = test_evaluation[TP]\n","test_fp = test_evaluation[FP]\n","test_tn = test_evaluation[TN]\n","test_fn = test_evaluation[FN]"]},{"cell_type":"markdown","metadata":{"id":"QhO0EAbfm_uc"},"source":["# Creating Reports for Each Trial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fc4nw6tBh1Qw"},"outputs":[],"source":["%%capture cap\n","best_train_accuracy = max(train_accuracy)\n","best_train_loss = min(train_loss)\n","\n","best_val_accuracy = max(validation_accuracy)\n","best_val_loss = min(validation_loss)\n","\n","good_train_index = train_accuracy.index(best_train_accuracy)\n","good_train_loss_index = train_loss.index(best_train_loss)\n","good_train_epoch = good_train_index + 1\n","good_train_loss_epoch = good_train_loss_index + 1\n","\n","good_val_index = validation_accuracy.index(best_val_accuracy)\n","good_val_loss_index = validation_loss.index(best_val_loss)\n","good_val_epoch = good_val_index + 1\n","good_val_loss_epoch = good_val_loss_index + 1\n","\n","\n","print(\"\\n============================ REPORT ==================================\")\n","print(model.summary())\n","print(\"\\t\\t\\tTrain\")\n","print(\"\\t\\tAccuracy\\tLoss\")\n","for i, accuracy_train in enumerate(train_accuracy):\n","  print(f\"Epoch {i + 1}: {accuracy_train}\\t{train_loss[i]}\")\n","\n","\n","\n","print(f\"\\nThe highest training accuracy value is {round(best_train_accuracy * 100, 2)}% at Epoch {good_train_epoch}\")\n","print(f\"The lowest training loss value is {round(best_train_loss, 2)} at Epoch {good_train_loss_epoch}\")\n","\n","\n","print(\"\\n\\t\\t\\tValidate\")\n","\n","for j, accuracy_validate in enumerate(validation_accuracy):\n","  print(f\"Epoch {j + 1}: {accuracy_validate}\\t{validation_loss[j]}\")\n","\n","\n","print(f\"\\nThe highest validation accuracy value is {round(best_val_accuracy * 100, 2)}% at Epoch {good_val_epoch}\")\n","print(f\"The lowest validation loss value is {round(best_val_loss, 2)} at Epoch {good_val_loss_epoch}\")\n","\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTrain Accuracy: \", train_accuracy)\n","print(\"\\nTrain Loss: \", train_loss)\n","print(\"\\nTrain Precision: \", train_precision)\n","print(\"\\nTrain Recall: \", train_recall)\n","print(\"\\nTrain True Positives: \", train_tp)\n","print(\"\\nTrain False Positives: \", train_fp)\n","print(\"\\nTrain True Negatives: \", train_tn)\n","print(\"\\nTrain False Negatives: \", train_fn)\n","\n","print(\"\\n\")\n","print(\"\\nValidation Accuracy: \", validation_accuracy)\n","print(\"\\nValidation Loss: \", validation_loss)\n","print(\"\\nValidation Precision: \", validation_precision)\n","print(\"\\nValidation Recall: \", validation_recall)\n","print(\"\\nValidation True Positives: \", validation_tp)\n","print(\"\\nValidation False Positives: \", validation_fp)\n","print(\"\\nValidation True Negatives: \", validation_tn)\n","print(\"\\nValidation False Negatives: \", validation_fn)\n","\n","print(\"\\n\")\n","print(\"\\t\\t\\tTest\")\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTest Accuracy: \", test_accuracy)\n","print(\"\\nTest Loss: \", test_loss)\n","print(\"\\nTest Precision: \", test_precision)\n","print(\"\\nTest Recall: \", test_recall)\n","print(\"\\nTest True Positives: \", test_tp)\n","print(\"\\nTest False Positives: \", test_fp)\n","print(\"\\nTest True Negatives: \", test_tn)\n","print(\"\\nTest False Negatives: \", test_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41BS4j2uh6fp"},"outputs":[],"source":["_# Uncomment to save file of output\n","f = open(\"trial4.txt\", \"w\") \n","print(cap, file=f)\n","files.download(\"/content/trial4.txt\")\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"9W93dCGkvKpz"},"source":["## Testing on Random Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyAMHWdz5PWy"},"outputs":[],"source":["# Uncomment to obtain CSV files\n","# Visualizing on benign tumors\n","test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant\"\n","\n","\n","# Create a data frame of benign tumors and show what the model predicts\n","test_labels_benign = create_dataframe(test_directory_benign, 0)\n","test_labels_malignant = create_dataframe(0, test_directory_malignant)\n","\n","\n","# Uncomment to save as CSV file and to download\n","# test_labels_benign.to_csv('test_labels_benign.csv')\n","# files.download('test_labels_benign.csv')\n","\n","# test_labels_malignant.to_csv('test_labels_malignant.csv')\n","# files.download('test_labels_malignant.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysxkBESv5ywQ"},"outputs":[],"source":["test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign/\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant/\"\n","\n","test_labels_benign_CSV = pd.read_csv(\"/content/drive/MyDrive/bioinformatics/data/test_labels_benign.csv\", index_col = 0)\n","test_paths_benign = [test_directory_benign + filename for filename in test_labels_benign_CSV[\"ID Benign\"]]\n","\n","test_labels_malignant_CSV = pd.read_csv(\"/content/drive/MyDrive/bioinformatics/data/test_labels_malignant.csv\", index_col = 0)\n","test_paths_malignant = [test_directory_malignant + filename for filename in test_labels_malignant_CSV[\"ID Malignant\"]]\n","\n","test_paths_benign[:5], test_paths_malignant[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unrwwi4WwMjq"},"outputs":[],"source":["# np.random.seed(42)\n","from PIL import Image\n","def visualize_test_images(paths, num_images):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    # Normalize image\n","    image = tf.keras.utils.load_img(paths[np.random.randint(0, num_images)])\n","    image = tf.keras.utils.img_to_array(image)\n","    image = image / 255\n","\n","    image_array = np.array(image)\n","    image_array.resize((1, 460, 700, 3))\n","\n","\n","    prediction = model_load.predict(image_array)\n","    result = round(prediction[0][0])\n","\n","    if result == BENIGN:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Benign\")\n","      plt.imshow(image)\n","    else:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Malignant\", color = \"red\")\n","      plt.imshow(image)\n","\n","    plt.axis(True)\n","visualize_test_images(test_paths_benign, 20)\n"]},{"cell_type":"markdown","metadata":{"id":"YQDHcpgoC0Q9"},"source":["# Using Transfer Learning to Compare Metrics with Pre-Built Models from TensorFlow Hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhEVC8ytTvZC"},"outputs":[],"source":["NUM_ROWS = 460\n","NUM_COLS = 700 \n","INPUT_SHAPE = [None, NUM_ROWS, NUM_COLS, 3]\n","OUTPUT_SHAPE = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4x0W4vnsIvf"},"outputs":[],"source":["def def_call_backs(model_name):\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 5, verbose = 1, mode = \"auto\")\n","  checkpoint = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/bioinformatics/\" + model_name + \".h5\", monitor = \"val_accuracy\", verbose = 1, mode = \"auto\", save_best_only = True)\n","  call_backs = [early_stopping, checkpoint]\n","  return call_backs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6tB2hYiWzgV"},"outputs":[],"source":["def transfer_learning(model_url):\n","  model = tf.keras.Sequential([hub.KerasLayer(model_url),\n","                                   tf.keras.layers.Dense(units = OUTPUT_SHAPE, activation = \"sigmoid\")])\n","  model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = metric_list)\n","  model.build(INPUT_SHAPE)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txrUlWU4tI30"},"outputs":[],"source":["def fit_model(model, model_name):\n","  # Fit the model\n","  call_backs = def_call_backs(model_name)\n","  model_fit = model.fit(x = train_data, epochs = 30, validation_data = validate_data, verbose = 1, callbacks = call_backs)\n","  model_history = model_fit.history\n","  return model_history"]},{"cell_type":"markdown","metadata":{"id":"aCcrHhSjWERr"},"source":["## Inception ResNet V2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-1KHa5sUwiE"},"outputs":[],"source":["inc_res_v2_model_url = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/5\"\n","IncResV2 = transfer_learning(inc_res_v2_model_url)\n","IncResV2_history = fit_model(IncResV2, \"IncResV2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwsJh1ZieF6y"},"outputs":[],"source":["train_accuracy = IncResV2_history[\"accuracy\"]\n","train_loss = IncResV2_history[\"loss\"]\n","train_precision = IncResV2_history[\"precision_2\"]\n","train_recall = IncResV2_history[\"recall_2\"]\n","train_tp = IncResV2_history[\"true_positives_2\"]\n","train_fp = IncResV2_history[\"false_positives_2\"]\n","train_tn = IncResV2_history[\"true_negatives_2\"]\n","train_fn = IncResV2_history[\"false_negatives_2\"]\n","\n","validation_accuracy = IncResV2_history[\"val_accuracy\"]\n","validation_loss = IncResV2_history[\"val_loss\"]\n","validation_precision = IncResV2_history[\"val_precision_2\"]\n","validation_recall = IncResV2_history[\"val_recall_2\"]\n","validation_tp = IncResV2_history[\"val_true_positives_2\"]\n","validation_fp = IncResV2_history[\"val_false_positives_2\"]\n","validation_tn = IncResV2_history[\"val_true_negatives_2\"]\n","validation_fn = IncResV2_history[\"val_false_negatives_2\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyDoAFesiZEx"},"outputs":[],"source":["train_acc, = plt.plot(train_accuracy, c = \"green\")\n","validate_acc, = plt.plot(validation_accuracy, c = \"red\")\n","plt.title(\"Train Accuracy vs. Validation Accuracy\")\n","plt.legend([train_acc, validate_acc],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgPeNtNaifYC"},"outputs":[],"source":["train_los, = plt.plot(train_loss, c = \"green\")\n","validate_los, = plt.plot(validation_loss, c = \"red\")\n","plt.title(\"Train Loss vs. Validation Loss\")\n","plt.legend([train_los, validate_los],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZSKGosNmpYg"},"outputs":[],"source":["IncResV2_load = tf.keras.models.load_model(\"/content/drive/MyDrive/bioinformatics/IncResV2.h5\", custom_objects = {\"KerasLayer\":hub.KerasLayer})\n","IncResV2_load.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGb9uG0nmYTH"},"outputs":[],"source":["IncResV2_test_evaluation = IncResV2_load.evaluate(x = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5I_v_Z5jpEw5"},"outputs":[],"source":["LOSS = 0\n","ACCURACY = 1\n","PRECISION = 2\n","RECALL =  3\n","TP = 4\n","FP = 5\n","TN = 6\n","FN = 7\n","\n","test_loss = IncResV2_test_evaluation[LOSS]\n","test_accuracy = IncResV2_test_evaluation[ACCURACY]\n","test_precision = IncResV2_test_evaluation[PRECISION]\n","test_recall = IncResV2_test_evaluation[RECALL]\n","test_tp = IncResV2_test_evaluation[TP]\n","test_fp = IncResV2_test_evaluation[FP]\n","test_tn = IncResV2_test_evaluation[TN]\n","test_fn = IncResV2_test_evaluation[FN]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2hMWuWLaiSy"},"outputs":[],"source":["%%capture cap\n","best_train_accuracy = max(train_accuracy)\n","best_train_loss = min(train_loss)\n","\n","best_val_accuracy = max(validation_accuracy)\n","best_val_loss = min(validation_loss)\n","\n","good_train_index = train_accuracy.index(best_train_accuracy)\n","good_train_loss_index = train_loss.index(best_train_loss)\n","good_train_epoch = good_train_index + 1\n","good_train_loss_epoch = good_train_loss_index + 1\n","\n","good_val_index = validation_accuracy.index(best_val_accuracy)\n","good_val_loss_index = validation_loss.index(best_val_loss)\n","good_val_epoch = good_val_index + 1\n","good_val_loss_epoch = good_val_loss_index + 1\n","\n","\n","print(\"\\n============================ REPORT ==================================\")\n","print(\"\\t\\t\\tTrain\")\n","print(\"\\t\\tAccuracy\\tLoss\")\n","for i, accuracy_train in enumerate(train_accuracy):\n","  print(f\"Epoch {i + 1}: {accuracy_train}\\t{train_loss[i]}\")\n","\n","\n","\n","print(f\"\\nThe highest training accuracy value is {round(best_train_accuracy * 100, 2)}% at Epoch {good_train_epoch}\")\n","print(f\"The lowest training loss value is {round(best_train_loss, 2)} at Epoch {good_train_loss_epoch}\")\n","\n","\n","print(\"\\n\\t\\t\\tValidate\")\n","\n","for j, accuracy_validate in enumerate(validation_accuracy):\n","  print(f\"Epoch {j + 1}: {accuracy_validate}\\t{validation_loss[j]}\")\n","\n","\n","print(f\"\\nThe highest validation accuracy value is {round(best_val_accuracy * 100, 2)}% at Epoch {good_val_epoch}\")\n","print(f\"The lowest validation loss value is {round(best_val_loss, 2)} at Epoch {good_val_loss_epoch}\")\n","\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTrain Accuracy: \", train_accuracy)\n","print(\"\\nTrain Loss: \", train_loss)\n","print(\"\\nTrain Precision: \", train_precision)\n","print(\"\\nTrain Recall: \", train_recall)\n","print(\"\\nTrain True Positives: \", train_tp)\n","print(\"\\nTrain False Positives: \", train_fp)\n","print(\"\\nTrain True Negatives: \", train_tn)\n","print(\"\\nTrain False Negatives: \", train_fn)\n","\n","print(\"\\n\")\n","print(\"\\nValidation Accuracy: \", validation_accuracy)\n","print(\"\\nValidation Loss: \", validation_loss)\n","print(\"\\nValidation Precision: \", validation_precision)\n","print(\"\\nValidation Recall: \", validation_recall)\n","print(\"\\nValidation True Positives: \", validation_tp)\n","print(\"\\nValidation False Positives: \", validation_fp)\n","print(\"\\nValidation True Negatives: \", validation_tn)\n","print(\"\\nValidation False Negatives: \", validation_fn)\n","\n","print(\"\\n\")\n","print(\"\\t\\t\\tTest\")\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTest Accuracy: \", test_accuracy)\n","print(\"\\nTest Loss: \", test_loss)\n","print(\"\\nTest Precision: \", test_precision)\n","print(\"\\nTest Recall: \", test_recall)\n","print(\"\\nTest True Positives: \", test_tp)\n","print(\"\\nTest False Positives: \", test_fp)\n","print(\"\\nTest True Negatives: \", test_tn)\n","print(\"\\nTest False Negatives: \", test_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpb2ojmfl1o8"},"outputs":[],"source":["f = open(\"trial5.txt\", \"w\") \n","print(cap, file=f)\n","files.download(\"/content/trial5.txt\")\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpgX-oBHmFOq"},"outputs":[],"source":["# Uncomment to obtain CSV files\n","# Visualizing on benign tumors\n","test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant\"\n","\n","\n","# Create a data frame of benign tumors and show what the model predicts\n","test_labels_benign = create_dataframe(test_directory_benign, 0)\n","test_labels_malignant = create_dataframe(0, test_directory_malignant)\n","\n","\n","# Uncomment to save as CSV file and to download\n","# test_labels_benign.to_csv('test_labels_benign.csv')\n","# files.download('test_labels_benign.csv')\n","\n","# test_labels_malignant.to_csv('test_labels_malignant.csv')\n","# files.download('test_labels_malignant.csv')"]},{"cell_type":"markdown","metadata":{"id":"K3vlb79-qwIo"},"source":["### Making Random Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0fbmH8cpvwB"},"outputs":[],"source":["# np.random.seed(42)\n","from PIL import Image\n","def visualize_test_images(paths, num_images, model):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    # Normalize image\n","    image = tf.keras.utils.load_img(paths[np.random.randint(0, num_images)])\n","    image = tf.keras.utils.img_to_array(image)\n","    image = image / 255\n","\n","    image_array = np.array(image)\n","    image_array.resize((1, 460, 700, 3))\n","\n","\n","    prediction = model.predict(image_array)\n","    result = round(prediction[0][0])\n","\n","    if result == BENIGN:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Benign\")\n","      plt.imshow(image)\n","    else:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Malignant\", color = \"red\")\n","      plt.imshow(image)\n","\n","\n","    plt.axis(True)\n","visualize_test_images(test_paths_malignant, 20, IncResV2_load)"]},{"cell_type":"markdown","metadata":{"id":"u7XuORC1t_YC"},"source":["## Efficient Net V2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILMj8xwsp0rD"},"outputs":[],"source":["eff_net_v2_model_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\"\n","EffNetV2 = transfer_learning(eff_net_v2_model_url)\n","EffNetV2_history = fit_model(EffNetV2, \"EffNetV2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFWt91Q8vC80"},"outputs":[],"source":["train_accuracy = EffNetV2_history[\"accuracy\"]\n","train_loss = EffNetV2_history[\"loss\"]\n","train_precision = EffNetV2_history[\"precision_2\"]\n","train_recall = EffNetV2_history[\"recall_2\"]\n","train_tp = EffNetV2_history[\"true_positives_2\"]\n","train_fp = EffNetV2_history[\"false_positives_2\"]\n","train_tn = EffNetV2_history[\"true_negatives_2\"]\n","train_fn = EffNetV2_history[\"false_negatives_2\"]\n","\n","validation_accuracy = EffNetV2_history[\"val_accuracy\"]\n","validation_loss = EffNetV2_history[\"val_loss\"]\n","validation_precision = EffNetV2_history[\"val_precision_2\"]\n","validation_recall = EffNetV2_history[\"val_recall_2\"]\n","validation_tp = EffNetV2_history[\"val_true_positives_2\"]\n","validation_fp = EffNetV2_history[\"val_false_positives_2\"]\n","validation_tn = EffNetV2_history[\"val_true_negatives_2\"]\n","validation_fn = EffNetV2_history[\"val_false_negatives_2\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Y78xCR2vDiu"},"outputs":[],"source":["train_acc, = plt.plot(train_accuracy, c = \"green\")\n","validate_acc, = plt.plot(validation_accuracy, c = \"red\")\n","plt.title(\"Train Accuracy vs. Validation Accuracy\")\n","plt.legend([train_acc, validate_acc],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZ8HNRDtKvML"},"outputs":[],"source":["train_los, = plt.plot(train_loss, c = \"green\")\n","validate_los, = plt.plot(validation_loss, c = \"red\")\n","plt.title(\"Train Loss vs. Validation Loss\")\n","plt.legend([train_los, validate_los],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93FXXbdOvITl"},"outputs":[],"source":["EffNetV2_load = tf.keras.models.load_model(\"/content/drive/MyDrive/bioinformatics/EffNetV2.h5\", custom_objects = {\"KerasLayer\":hub.KerasLayer})\n","EffNetV2_load.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"il6e0CntvLL4"},"outputs":[],"source":["EffNetV2_test_evaluation = EffNetV2_load.evaluate(x = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeiC8U9VvL3n"},"outputs":[],"source":["LOSS = 0\n","ACCURACY = 1\n","PRECISION = 2\n","RECALL =  3\n","TP = 4\n","FP = 5\n","TN = 6\n","FN = 7\n","\n","test_loss = EffNetV2_test_evaluation[LOSS]\n","test_accuracy = EffNetV2_test_evaluation[ACCURACY]\n","test_precision = EffNetV2_test_evaluation[PRECISION]\n","test_recall = EffNetV2_test_evaluation[RECALL]\n","test_tp = EffNetV2_test_evaluation[TP]\n","test_fp = EffNetV2_test_evaluation[FP]\n","test_tn = EffNetV2_test_evaluation[TN]\n","test_fn = EffNetV2_test_evaluation[FN]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Weog8UczvTbi"},"outputs":[],"source":["%%capture cap\n","best_train_accuracy = max(train_accuracy)\n","best_train_loss = min(train_loss)\n","\n","best_val_accuracy = max(validation_accuracy)\n","best_val_loss = min(validation_loss)\n","\n","good_train_index = train_accuracy.index(best_train_accuracy)\n","good_train_loss_index = train_loss.index(best_train_loss)\n","good_train_epoch = good_train_index + 1\n","good_train_loss_epoch = good_train_loss_index + 1\n","\n","good_val_index = validation_accuracy.index(best_val_accuracy)\n","good_val_loss_index = validation_loss.index(best_val_loss)\n","good_val_epoch = good_val_index + 1\n","good_val_loss_epoch = good_val_loss_index + 1\n","\n","\n","print(\"\\n============================ REPORT ==================================\")\n","print(\"\\t\\t\\tTrain\")\n","print(\"\\t\\tAccuracy\\tLoss\")\n","for i, accuracy_train in enumerate(train_accuracy):\n","  print(f\"Epoch {i + 1}: {accuracy_train}\\t{train_loss[i]}\")\n","\n","\n","\n","print(f\"\\nThe highest training accuracy value is {round(best_train_accuracy * 100, 2)}% at Epoch {good_train_epoch}\")\n","print(f\"The lowest training loss value is {round(best_train_loss, 2)} at Epoch {good_train_loss_epoch}\")\n","\n","\n","print(\"\\n\\t\\t\\tValidate\")\n","\n","for j, accuracy_validate in enumerate(validation_accuracy):\n","  print(f\"Epoch {j + 1}: {accuracy_validate}\\t{validation_loss[j]}\")\n","\n","\n","print(f\"\\nThe highest validation accuracy value is {round(best_val_accuracy * 100, 2)}% at Epoch {good_val_epoch}\")\n","print(f\"The lowest validation loss value is {round(best_val_loss, 2)} at Epoch {good_val_loss_epoch}\")\n","\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTrain Accuracy: \", train_accuracy)\n","print(\"\\nTrain Loss: \", train_loss)\n","print(\"\\nTrain Precision: \", train_precision)\n","print(\"\\nTrain Recall: \", train_recall)\n","print(\"\\nTrain True Positives: \", train_tp)\n","print(\"\\nTrain False Positives: \", train_fp)\n","print(\"\\nTrain True Negatives: \", train_tn)\n","print(\"\\nTrain False Negatives: \", train_fn)\n","\n","print(\"\\n\")\n","print(\"\\nValidation Accuracy: \", validation_accuracy)\n","print(\"\\nValidation Loss: \", validation_loss)\n","print(\"\\nValidation Precision: \", validation_precision)\n","print(\"\\nValidation Recall: \", validation_recall)\n","print(\"\\nValidation True Positives: \", validation_tp)\n","print(\"\\nValidation False Positives: \", validation_fp)\n","print(\"\\nValidation True Negatives: \", validation_tn)\n","print(\"\\nValidation False Negatives: \", validation_fn)\n","\n","print(\"\\n\")\n","print(\"\\t\\t\\tTest\")\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTest Accuracy: \", test_accuracy)\n","print(\"\\nTest Loss: \", test_loss)\n","print(\"\\nTest Precision: \", test_precision)\n","print(\"\\nTest Recall: \", test_recall)\n","print(\"\\nTest True Positives: \", test_tp)\n","print(\"\\nTest False Positives: \", test_fp)\n","print(\"\\nTest True Negatives: \", test_tn)\n","print(\"\\nTest False Negatives: \", test_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8041q4vvbJe"},"outputs":[],"source":["f = open(\"trial6.txt\", \"w\") \n","print(cap, file=f)\n","files.download(\"/content/trial6.txt\")\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"8cnY7Ld5Sgh3"},"source":["### Making Random Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gNjgfhpMXOM"},"outputs":[],"source":["# Uncomment to obtain CSV files\n","# Visualizing on benign tumors\n","test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant\"\n","\n","\n","# Create a data frame of benign tumors and show what the model predicts\n","test_labels_benign = create_dataframe(test_directory_benign, 0)\n","test_labels_malignant = create_dataframe(0, test_directory_malignant)\n","\n","\n","# Uncomment to save as CSV file and to download\n","# test_labels_benign.to_csv('test_labels_benign.csv')\n","# files.download('test_labels_benign.csv')\n","\n","# test_labels_malignant.to_csv('test_labels_malignant.csv')\n","# files.download('test_labels_malignant.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xey-ziROMzs2"},"outputs":[],"source":["# np.random.seed(42)\n","from PIL import Image\n","def visualize_test_images(paths, num_images, model):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    # Normalize image\n","    image = tf.keras.utils.load_img(paths[np.random.randint(0, num_images)])\n","    image = tf.keras.utils.img_to_array(image)\n","    image = image / 255\n","\n","    image_array = np.array(image)\n","    image_array.resize((1, 460, 700, 3))\n","\n","\n","    prediction = model.predict(image_array)\n","    result = round(prediction[0][0])\n","\n","    if result == BENIGN:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Benign\")\n","      plt.imshow(image)\n","    else:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Malignant\", color = \"red\")\n","      plt.imshow(image)\n","\n","\n","    plt.axis(True)\n","visualize_test_images(test_paths_malignant, 20, EffNetV2_load)"]},{"cell_type":"markdown","metadata":{"id":"ZWaVdx18Nn52"},"source":["## Efficient Net B7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yo_dIdyFM6vi"},"outputs":[],"source":["eff_net_b7_model_url = \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\"\n","EffNetB7 = transfer_learning(eff_net_b7_model_url)\n","EffNetB7_history = fit_model(EffNetB7, \"EffNetB7\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZV67O1TSNwNa"},"outputs":[],"source":["train_accuracy = EffNetB7_history[\"accuracy\"]\n","train_loss = EffNetB7_history[\"loss\"]\n","train_precision = EffNetB7_history[\"precision_2\"]\n","train_recall = EffNetB7_history[\"recall_2\"]\n","train_tp = EffNetB7_history[\"true_positives_2\"]\n","train_fp = EffNetB7_history[\"false_positives_2\"]\n","train_tn = EffNetB7_history[\"true_negatives_2\"]\n","train_fn = EffNetB7_history[\"false_negatives_2\"]\n","\n","validation_accuracy = EffNetB7_history[\"val_accuracy\"]\n","validation_loss = EffNetB7_history[\"val_loss\"]\n","validation_precision = EffNetB7_history[\"val_precision_2\"]\n","validation_recall = EffNetB7_history[\"val_recall_2\"]\n","validation_tp = EffNetB7_history[\"val_true_positives_2\"]\n","validation_fp = EffNetB7_history[\"val_false_positives_2\"]\n","validation_tn = EffNetB7_history[\"val_true_negatives_2\"]\n","validation_fn = EffNetB7_history[\"val_false_negatives_2\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCdHGcGsOVwQ"},"outputs":[],"source":["train_acc, = plt.plot(train_accuracy, c = \"green\")\n","validate_acc, = plt.plot(validation_accuracy, c = \"red\")\n","plt.title(\"Train Accuracy vs. Validation Accuracy\")\n","plt.legend([train_acc, validate_acc],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DX9MUNhOYpZ"},"outputs":[],"source":["train_los, = plt.plot(train_loss, c = \"green\")\n","validate_los, = plt.plot(validation_loss, c = \"red\")\n","plt.title(\"Train Loss vs. Validation Loss\")\n","plt.legend([train_los, validate_los],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWMWmQblOcXS"},"outputs":[],"source":["EffNetB7_load = tf.keras.models.load_model(\"/content/drive/MyDrive/bioinformatics/EffNetB7.h5\", custom_objects = {\"KerasLayer\":hub.KerasLayer})\n","EffNetB7_load.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLwoLaVaR5kt"},"outputs":[],"source":["EffNetB7_test_evaluation = EffNetB7_load.evaluate(x = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpXe-aITSHgz"},"outputs":[],"source":["LOSS = 0\n","ACCURACY = 1\n","PRECISION = 2\n","RECALL =  3\n","TP = 4\n","FP = 5\n","TN = 6\n","FN = 7\n","\n","test_loss = EffNetB7_test_evaluation[LOSS]\n","test_accuracy = EffNetB7_test_evaluation[ACCURACY]\n","test_precision = EffNetB7_test_evaluation[PRECISION]\n","test_recall = EffNetB7_test_evaluation[RECALL]\n","test_tp = EffNetB7_test_evaluation[TP]\n","test_fp = EffNetB7_test_evaluation[FP]\n","test_tn = EffNetB7_test_evaluation[TN]\n","test_fn = EffNetB7_test_evaluation[FN]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3XKHByXSGZN"},"outputs":[],"source":["%%capture cap\n","best_train_accuracy = max(train_accuracy)\n","best_train_loss = min(train_loss)\n","\n","best_val_accuracy = max(validation_accuracy)\n","best_val_loss = min(validation_loss)\n","\n","good_train_index = train_accuracy.index(best_train_accuracy)\n","good_train_loss_index = train_loss.index(best_train_loss)\n","good_train_epoch = good_train_index + 1\n","good_train_loss_epoch = good_train_loss_index + 1\n","\n","good_val_index = validation_accuracy.index(best_val_accuracy)\n","good_val_loss_index = validation_loss.index(best_val_loss)\n","good_val_epoch = good_val_index + 1\n","good_val_loss_epoch = good_val_loss_index + 1\n","\n","\n","print(\"\\n============================ REPORT ==================================\")\n","print(\"\\t\\t\\tTrain\")\n","print(\"\\t\\tAccuracy\\tLoss\")\n","for i, accuracy_train in enumerate(train_accuracy):\n","  print(f\"Epoch {i + 1}: {accuracy_train}\\t{train_loss[i]}\")\n","\n","\n","\n","print(f\"\\nThe highest training accuracy value is {round(best_train_accuracy * 100, 2)}% at Epoch {good_train_epoch}\")\n","print(f\"The lowest training loss value is {round(best_train_loss, 2)} at Epoch {good_train_loss_epoch}\")\n","\n","\n","print(\"\\n\\t\\t\\tValidate\")\n","\n","for j, accuracy_validate in enumerate(validation_accuracy):\n","  print(f\"Epoch {j + 1}: {accuracy_validate}\\t{validation_loss[j]}\")\n","\n","\n","print(f\"\\nThe highest validation accuracy value is {round(best_val_accuracy * 100, 2)}% at Epoch {good_val_epoch}\")\n","print(f\"The lowest validation loss value is {round(best_val_loss, 2)} at Epoch {good_val_loss_epoch}\")\n","\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTrain Accuracy: \", train_accuracy)\n","print(\"\\nTrain Loss: \", train_loss)\n","print(\"\\nTrain Precision: \", train_precision)\n","print(\"\\nTrain Recall: \", train_recall)\n","print(\"\\nTrain True Positives: \", train_tp)\n","print(\"\\nTrain False Positives: \", train_fp)\n","print(\"\\nTrain True Negatives: \", train_tn)\n","print(\"\\nTrain False Negatives: \", train_fn)\n","\n","print(\"\\n\")\n","print(\"\\nValidation Accuracy: \", validation_accuracy)\n","print(\"\\nValidation Loss: \", validation_loss)\n","print(\"\\nValidation Precision: \", validation_precision)\n","print(\"\\nValidation Recall: \", validation_recall)\n","print(\"\\nValidation True Positives: \", validation_tp)\n","print(\"\\nValidation False Positives: \", validation_fp)\n","print(\"\\nValidation True Negatives: \", validation_tn)\n","print(\"\\nValidation False Negatives: \", validation_fn)\n","\n","print(\"\\n\")\n","print(\"\\t\\t\\tTest\")\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTest Accuracy: \", test_accuracy)\n","print(\"\\nTest Loss: \", test_loss)\n","print(\"\\nTest Precision: \", test_precision)\n","print(\"\\nTest Recall: \", test_recall)\n","print(\"\\nTest True Positives: \", test_tp)\n","print(\"\\nTest False Positives: \", test_fp)\n","print(\"\\nTest True Negatives: \", test_tn)\n","print(\"\\nTest False Negatives: \", test_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blklg7yYSLTt"},"outputs":[],"source":["f = open(\"trial7.txt\", \"w\") \n","print(cap, file=f)\n","files.download(\"/content/trial7.txt\")\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"ECiqckVKcFlL"},"source":["### Making Random Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOROdWKBSR8Z"},"outputs":[],"source":["# Uncomment to obtain CSV files\n","# Visualizing on benign tumors\n","test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant\"\n","\n","\n","# Create a data frame of benign tumors and show what the model predicts\n","test_labels_benign = create_dataframe(test_directory_benign, 0)\n","test_labels_malignant = create_dataframe(0, test_directory_malignant)\n","\n","\n","# Uncomment to save as CSV file and to download\n","# test_labels_benign.to_csv('test_labels_benign.csv')\n","# files.download('test_labels_benign.csv')\n","\n","# test_labels_malignant.to_csv('test_labels_malignant.csv')\n","# files.download('test_labels_malignant.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkwofuGESS0I"},"outputs":[],"source":["# np.random.seed(42)\n","from PIL import Image\n","def visualize_test_images(paths, num_images, model):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    # Normalize image\n","    image = tf.keras.utils.load_img(paths[np.random.randint(0, num_images)])\n","    image = tf.keras.utils.img_to_array(image)\n","    image = image / 255\n","\n","    image_array = np.array(image)\n","    image_array.resize((1, 460, 700, 3))\n","\n","\n","    prediction = model.predict(image_array)\n","    result = round(prediction[0][0])\n","\n","    if result == BENIGN:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Benign\")\n","      plt.imshow(image)\n","    else:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Malignant\", color = \"red\")\n","      plt.imshow(image)\n","\n","    plt.axis(True)\n","visualize_test_images(test_paths_malignant, 20, EffNetB7_load)"]},{"cell_type":"markdown","metadata":{"id":"4ql2XiX9VooL"},"source":["## Inception V3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ql2MmoqFTCrM"},"outputs":[],"source":["inc_v3_model_url = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n","IncV3 = transfer_learning(inc_v3_model_url)\n","IncV3_history = fit_model(IncV3, \"IncV3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tITSRTPOUDUr"},"outputs":[],"source":["train_accuracy = IncV3_history[\"accuracy\"]\n","train_loss = IncV3_history[\"loss\"]\n","train_precision = IncV3_history[\"precision_2\"]\n","train_recall = IncV3_history[\"recall_2\"]\n","train_tp = IncV3_history[\"true_positives_2\"]\n","train_fp = IncV3_history[\"false_positives_2\"]\n","train_tn = IncV3_history[\"true_negatives_2\"]\n","train_fn = IncV3_history[\"false_negatives_2\"]\n","\n","validation_accuracy = IncV3_history[\"val_accuracy\"]\n","validation_loss = IncV3_history[\"val_loss\"]\n","validation_precision = IncV3_history[\"val_precision_2\"]\n","validation_recall = IncV3_history[\"val_recall_2\"]\n","validation_tp = IncV3_history[\"val_true_positives_2\"]\n","validation_fp = IncV3_history[\"val_false_positives_2\"]\n","validation_tn = IncV3_history[\"val_true_negatives_2\"]\n","validation_fn = IncV3_history[\"val_false_negatives_2\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivp5RAcLUG7J"},"outputs":[],"source":["train_acc, = plt.plot(train_accuracy, c = \"green\")\n","validate_acc, = plt.plot(validation_accuracy, c = \"red\")\n","plt.title(\"Train Accuracy vs. Validation Accuracy\")\n","plt.legend([train_acc, validate_acc],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUR5YVFLULCS"},"outputs":[],"source":["train_los, = plt.plot(train_loss, c = \"green\")\n","validate_los, = plt.plot(validation_loss, c = \"red\")\n","plt.title(\"Train Loss vs. Validation Loss\")\n","plt.legend([train_los, validate_los],[\"Training\", \"Validation\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDP9AkNXUO1F"},"outputs":[],"source":["IncV3_load = tf.keras.models.load_model(\"/content/drive/MyDrive/bioinformatics/IncV3.h5\", custom_objects = {\"KerasLayer\":hub.KerasLayer})\n","IncV3_load.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvWgiLYaWPyJ"},"outputs":[],"source":["IncV3_test_evaluation = IncV3_load.evaluate(x = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lMZpQR8VSx_"},"outputs":[],"source":["LOSS = 0\n","ACCURACY = 1\n","PRECISION = 2\n","RECALL =  3\n","TP = 4\n","FP = 5\n","TN = 6\n","FN = 7\n","\n","test_loss = IncV3_test_evaluation[LOSS]\n","test_accuracy = IncV3_test_evaluation[ACCURACY]\n","test_precision = IncV3_test_evaluation[PRECISION]\n","test_recall = IncV3_test_evaluation[RECALL]\n","test_tp = IncV3_test_evaluation[TP]\n","test_fp = IncV3_test_evaluation[FP]\n","test_tn = IncV3_test_evaluation[TN]\n","test_fn = IncV3_test_evaluation[FN]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hl2hAJPNVUwC"},"outputs":[],"source":["%%capture cap\n","best_train_accuracy = max(train_accuracy)\n","best_train_loss = min(train_loss)\n","\n","best_val_accuracy = max(validation_accuracy)\n","best_val_loss = min(validation_loss)\n","\n","good_train_index = train_accuracy.index(best_train_accuracy)\n","good_train_loss_index = train_loss.index(best_train_loss)\n","good_train_epoch = good_train_index + 1\n","good_train_loss_epoch = good_train_loss_index + 1\n","\n","good_val_index = validation_accuracy.index(best_val_accuracy)\n","good_val_loss_index = validation_loss.index(best_val_loss)\n","good_val_epoch = good_val_index + 1\n","good_val_loss_epoch = good_val_loss_index + 1\n","\n","\n","print(\"\\n============================ REPORT ==================================\")\n","print(\"\\t\\t\\tTrain\")\n","print(\"\\t\\tAccuracy\\tLoss\")\n","for i, accuracy_train in enumerate(train_accuracy):\n","  print(f\"Epoch {i + 1}: {accuracy_train}\\t{train_loss[i]}\")\n","\n","\n","\n","print(f\"\\nThe highest training accuracy value is {round(best_train_accuracy * 100, 2)}% at Epoch {good_train_epoch}\")\n","print(f\"The lowest training loss value is {round(best_train_loss, 2)} at Epoch {good_train_loss_epoch}\")\n","\n","\n","print(\"\\n\\t\\t\\tValidate\")\n","\n","for j, accuracy_validate in enumerate(validation_accuracy):\n","  print(f\"Epoch {j + 1}: {accuracy_validate}\\t{validation_loss[j]}\")\n","\n","\n","print(f\"\\nThe highest validation accuracy value is {round(best_val_accuracy * 100, 2)}% at Epoch {good_val_epoch}\")\n","print(f\"The lowest validation loss value is {round(best_val_loss, 2)} at Epoch {good_val_loss_epoch}\")\n","\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTrain Accuracy: \", train_accuracy)\n","print(\"\\nTrain Loss: \", train_loss)\n","print(\"\\nTrain Precision: \", train_precision)\n","print(\"\\nTrain Recall: \", train_recall)\n","print(\"\\nTrain True Positives: \", train_tp)\n","print(\"\\nTrain False Positives: \", train_fp)\n","print(\"\\nTrain True Negatives: \", train_tn)\n","print(\"\\nTrain False Negatives: \", train_fn)\n","\n","print(\"\\n\")\n","print(\"\\nValidation Accuracy: \", validation_accuracy)\n","print(\"\\nValidation Loss: \", validation_loss)\n","print(\"\\nValidation Precision: \", validation_precision)\n","print(\"\\nValidation Recall: \", validation_recall)\n","print(\"\\nValidation True Positives: \", validation_tp)\n","print(\"\\nValidation False Positives: \", validation_fp)\n","print(\"\\nValidation True Negatives: \", validation_tn)\n","print(\"\\nValidation False Negatives: \", validation_fn)\n","\n","print(\"\\n\")\n","print(\"\\t\\t\\tTest\")\n","print(\"------------------------------------------------------------------------\")\n","print(\"\\nTest Accuracy: \", test_accuracy)\n","print(\"\\nTest Loss: \", test_loss)\n","print(\"\\nTest Precision: \", test_precision)\n","print(\"\\nTest Recall: \", test_recall)\n","print(\"\\nTest True Positives: \", test_tp)\n","print(\"\\nTest False Positives: \", test_fp)\n","print(\"\\nTest True Negatives: \", test_tn)\n","print(\"\\nTest False Negatives: \", test_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNbsbSlYVYu_"},"outputs":[],"source":["f = open(\"trial8.txt\", \"w\") \n","print(cap, file=f)\n","files.download(\"/content/trial8.txt\")\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"1cDSIW2Cb428"},"source":["### Making Random Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uZoNGmrVeTt"},"outputs":[],"source":["# Uncomment to obtain CSV files\n","# Visualizing on benign tumors\n","test_directory_benign = \"/content/drive/MyDrive/bioinformatics/data/test/benign\"\n","test_directory_malignant = \"/content/drive/MyDrive/bioinformatics/data/test/malignant\"\n","\n","\n","# Create a data frame of benign tumors and show what the model predicts\n","test_labels_benign = create_dataframe(test_directory_benign, 0)\n","test_labels_malignant = create_dataframe(0, test_directory_malignant)\n","\n","\n","# Uncomment to save as CSV file and to download\n","# test_labels_benign.to_csv('test_labels_benign.csv')\n","# files.download('test_labels_benign.csv')\n","\n","# test_labels_malignant.to_csv('test_labels_malignant.csv')\n","# files.download('test_labels_malignant.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAOANaD6Vew5"},"outputs":[],"source":["# np.random.seed(42)\n","from PIL import Image\n","def visualize_test_images(paths, num_images, model):\n","  plt.figure(figsize = (15, 15))\n","\n","  for i in range(num_images):\n","    # Normalize image\n","    image = tf.keras.utils.load_img(paths[np.random.randint(0, num_images)])\n","    image = tf.keras.utils.img_to_array(image)\n","    image = image / 255\n","\n","    image_array = np.array(image)\n","    image_array.resize((1, 460, 700, 3))\n","\n","\n","    prediction = model.predict(image_array)\n","    result = round(prediction[0][0])\n","\n","    if result == BENIGN:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Benign\")\n","      plt.imshow(image)\n","    else:\n","      ax = plt.subplot(5, 4, i + 1)\n","      plt.xlabel(str(i))\n","      plt.title(\"Malignant\", color = \"red\")\n","      plt.imshow(image)\n","\n","    plt.axis(True)\n","visualize_test_images(test_paths_malignant, 20, IncV3_load)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMFci0EJbgHu"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["u7XuORC1t_YC","ZWaVdx18Nn52","4ql2XiX9VooL"],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
